{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_translated_all = \"corpora/subtitles/translations/opus10_whole.txt\"\n",
    "with open(filename_translated_all, \"rt\", encoding=\"utf-8\") as f:\n",
    "    translated_all = [line.rstrip() for line in f.readlines()]\n",
    "len(translated_all)\n",
    "\n",
    "with open(\"subtitles_raw/en_raw_0-900.txt\", \"rt\", encoding=\"utf-8\") as f:\n",
    "    en_all = [line.strip() for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lvwerra/test',\n",
       " 'precision',\n",
       " 'code_eval',\n",
       " 'roc_auc',\n",
       " 'cuad',\n",
       " 'xnli',\n",
       " 'rouge',\n",
       " 'pearsonr',\n",
       " 'mse',\n",
       " 'super_glue',\n",
       " 'comet',\n",
       " 'cer',\n",
       " 'sacrebleu',\n",
       " 'mahalanobis',\n",
       " 'wer',\n",
       " 'competition_math',\n",
       " 'f1',\n",
       " 'recall',\n",
       " 'coval',\n",
       " 'mauve',\n",
       " 'xtreme_s',\n",
       " 'bleurt',\n",
       " 'ter',\n",
       " 'accuracy',\n",
       " 'exact_match',\n",
       " 'indic_glue',\n",
       " 'spearmanr',\n",
       " 'mae',\n",
       " 'squad',\n",
       " 'chrf',\n",
       " 'glue',\n",
       " 'perplexity',\n",
       " 'mean_iou',\n",
       " 'squad_v2',\n",
       " 'meteor',\n",
       " 'bleu',\n",
       " 'wiki_split',\n",
       " 'sari',\n",
       " 'frugalscore',\n",
       " 'google_bleu',\n",
       " 'bertscore',\n",
       " 'matthews_correlation',\n",
       " 'seqeval',\n",
       " 'trec_eval',\n",
       " 'rl_reliability',\n",
       " 'jordyvl/ece',\n",
       " 'angelina-wang/directional_bias_amplification',\n",
       " 'cpllab/syntaxgym',\n",
       " 'lvwerra/bary_score',\n",
       " 'kaggle/amex',\n",
       " 'kaggle/ai4code',\n",
       " 'hack/test_metric',\n",
       " 'yzha/ctc_eval',\n",
       " 'codeparrot/apps_metric',\n",
       " 'mfumanelli/geometric_mean',\n",
       " 'daiyizheng/valid',\n",
       " 'poseval',\n",
       " 'erntkn/dice_coefficient',\n",
       " 'mgfrantz/roc_auc_macro',\n",
       " 'Vlasta/pr_auc',\n",
       " 'gorkaartola/metric_for_tp_fp_samples',\n",
       " 'idsedykh/metric',\n",
       " 'idsedykh/codebleu2',\n",
       " 'idsedykh/codebleu',\n",
       " 'idsedykh/megaglue',\n",
       " 'cakiki/ndcg',\n",
       " 'brier_score',\n",
       " 'Vertaix/vendiscore',\n",
       " 'GMFTBY/dailydialogevaluate',\n",
       " 'GMFTBY/dailydialog_evaluate',\n",
       " 'jzm-mailchimp/joshs_second_test_metric',\n",
       " 'ola13/precision_at_k',\n",
       " 'yulong-me/yl_metric',\n",
       " 'abidlabs/mean_iou',\n",
       " 'abidlabs/mean_iou2',\n",
       " 'KevinSpaghetti/accuracyk',\n",
       " 'NimaBoscarino/weat',\n",
       " 'ronaldahmed/nwentfaithfulness',\n",
       " 'Viona/infolm',\n",
       " 'kyokote/my_metric2',\n",
       " 'kashif/mape',\n",
       " 'Ochiroo/rouge_mn',\n",
       " 'giulio98/code_eval_outputs',\n",
       " 'leslyarun/fbeta_score',\n",
       " 'giulio98/codebleu',\n",
       " 'anz2/iliauniiccocrevaluation',\n",
       " 'zbeloki/m2',\n",
       " 'xu1998hz/sescore',\n",
       " 'mase',\n",
       " 'mape',\n",
       " 'smape',\n",
       " 'dvitel/codebleu',\n",
       " 'NCSOFT/harim_plus',\n",
       " 'JP-SystemsX/nDCG',\n",
       " 'sportlosos/sescore',\n",
       " 'Drunper/metrica_tesi',\n",
       " 'jpxkqx/peak_signal_to_noise_ratio',\n",
       " 'jpxkqx/signal_to_reconstrution_error',\n",
       " 'hpi-dhc/FairEval',\n",
       " 'nist_mt',\n",
       " 'lvwerra/accuracy_score',\n",
       " 'character',\n",
       " 'charcut_mt',\n",
       " 'ybelkada/cocoevaluate',\n",
       " 'harshhpareek/bertscore',\n",
       " 'posicube/mean_reciprocal_rank',\n",
       " 'bstrai/classification_report',\n",
       " 'omidf/squad_precision_recall',\n",
       " 'Josh98/nl2bash_m',\n",
       " 'BucketHeadP65/confusion_matrix',\n",
       " 'BucketHeadP65/roc_curve',\n",
       " 'yonting/average_precision_score',\n",
       " 'transZ/test_parascore',\n",
       " 'transZ/sbert_cosine',\n",
       " 'hynky/sklearn_proxy',\n",
       " 'xu1998hz/sescore_english_mt',\n",
       " 'xu1998hz/sescore_german_mt',\n",
       " 'xu1998hz/sescore_english_coco',\n",
       " 'xu1998hz/sescore_english_webnlg',\n",
       " 'unnati/kendall_tau_distance',\n",
       " 'r_squared',\n",
       " 'Viona/fuzzy_reordering',\n",
       " 'Viona/kendall_tau',\n",
       " 'lhy/hamming_loss',\n",
       " 'lhy/ranking_loss',\n",
       " 'Muennighoff/code_eval',\n",
       " 'yuyijiong/quad_match_score',\n",
       " 'Splend1dchan/cosine_similarity',\n",
       " 'Yeshwant123/mcc',\n",
       " 'transformersegmentation/segmentation_scores',\n",
       " 'sma2023/wil',\n",
       " 'chanelcolgate/average_precision',\n",
       " 'ckb/unigram',\n",
       " 'Felipehonorato/eer',\n",
       " 'manueldeprada/beer',\n",
       " 'tialaeMceryu/unigram',\n",
       " 'shunzh/apps_metric',\n",
       " 'hxw15/sari_metric',\n",
       " 'mcnemar',\n",
       " 'exact_match',\n",
       " 'wilcoxon',\n",
       " 'ncoop57/levenshtein_distance',\n",
       " 'kaleidophon/almost_stochastic_order',\n",
       " 'word_length',\n",
       " 'lvwerra/element_count',\n",
       " 'word_count',\n",
       " 'text_duplicates',\n",
       " 'perplexity',\n",
       " 'label_distribution',\n",
       " 'toxicity',\n",
       " 'prb977/cooccurrence_count',\n",
       " 'regard',\n",
       " 'honest',\n",
       " 'NimaBoscarino/pseudo_perplexity',\n",
       " 'ybelkada/toxicity',\n",
       " 'ronaldahmed/ccl_win',\n",
       " 'meg/perplexity']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate.list_evaluation_modules() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d0bedff87c14614a817c5d3f5ad5807",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/7.95k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "EvaluationModule(name: \"bert_score\", module_type: \"metric\", features: [{'predictions': Value(dtype='string', id='sequence'), 'references': Sequence(feature=Value(dtype='string', id='sequence'), length=-1, id='references')}, {'predictions': Value(dtype='string', id='sequence'), 'references': Value(dtype='string', id='sequence')}], usage: \"\"\"\n",
       "BERTScore Metrics with the hashcode from a source against one or more references.\n",
       "\n",
       "Args:\n",
       "    predictions (list of str): Prediction/candidate sentences.\n",
       "    references (list of str or list of list of str): Reference sentences.\n",
       "    lang (str): Language of the sentences; required (e.g. 'en').\n",
       "    model_type (str): Bert specification, default using the suggested\n",
       "        model for the target language; has to specify at least one of\n",
       "        `model_type` or `lang`.\n",
       "    num_layers (int): The layer of representation to use,\n",
       "        default using the number of layers tuned on WMT16 correlation data.\n",
       "    verbose (bool): Turn on intermediate status update.\n",
       "    idf (bool or dict): Use idf weighting; can also be a precomputed idf_dict.\n",
       "    device (str): On which the contextual embedding model will be allocated on.\n",
       "        If this argument is None, the model lives on cuda:0 if cuda is available.\n",
       "    nthreads (int): Number of threads.\n",
       "    batch_size (int): Bert score processing batch size,\n",
       "        at least one of `model_type` or `lang`. `lang` needs to be\n",
       "        specified when `rescale_with_baseline` is True.\n",
       "    rescale_with_baseline (bool): Rescale bertscore with pre-computed baseline.\n",
       "    baseline_path (str): Customized baseline file.\n",
       "    use_fast_tokenizer (bool): `use_fast` parameter passed to HF tokenizer. New in version 0.3.10.\n",
       "\n",
       "Returns:\n",
       "    precision: Precision.\n",
       "    recall: Recall.\n",
       "    f1: F1 score.\n",
       "    hashcode: Hashcode of the library.\n",
       "\n",
       "Examples:\n",
       "\n",
       "    >>> predictions = [\"hello there\", \"general kenobi\"]\n",
       "    >>> references = [\"hello there\", \"general kenobi\"]\n",
       "    >>> bertscore = evaluate.load(\"bertscore\")\n",
       "    >>> results = bertscore.compute(predictions=predictions, references=references, lang=\"en\")\n",
       "    >>> print([round(v, 2) for v in results[\"f1\"]])\n",
       "    [1.0, 1.0]\n",
       "\"\"\", stored examples: 0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate.load('bertscore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bertscore = evaluate.load(\"bertscore\")\n",
    "predictions = [\"hello there\"]\n",
    "references = [\"hello there\"]\n",
    "results = bertscore.compute(predictions=predictions, references=references, lang=\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision': [1.0000001192092896],\n",
       " 'recall': [1.0000001192092896],\n",
       " 'f1': [1.0000001192092896],\n",
       " 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.27.4)'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bertscore = evaluate.load(\"bertscore\")\n",
    "predictions = translated_all[:100]\n",
    "references = en_all[:100]\n",
    "results = bertscore.compute(predictions=predictions, references=references, lang=\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision': [0.9832838773727417,\n",
       "  0.9125242233276367,\n",
       "  0.9337339997291565,\n",
       "  0.9342162013053894,\n",
       "  0.9147887229919434,\n",
       "  0.955983579158783,\n",
       "  0.971820592880249,\n",
       "  0.9054244160652161,\n",
       "  0.8439466953277588,\n",
       "  0.9611888527870178,\n",
       "  0.9365171194076538,\n",
       "  0.8374711871147156,\n",
       "  0.9013276100158691,\n",
       "  0.951059877872467,\n",
       "  0.9269106984138489,\n",
       "  0.959517776966095,\n",
       "  0.9426910877227783,\n",
       "  0.9069293737411499,\n",
       "  0.8461410999298096,\n",
       "  0.8147189021110535,\n",
       "  0.8580019474029541,\n",
       "  0.8450736999511719,\n",
       "  0.8341739177703857,\n",
       "  0.8793951272964478,\n",
       "  0.9068586230278015,\n",
       "  0.9967114925384521,\n",
       "  0.9226245284080505,\n",
       "  0.9899012446403503,\n",
       "  0.8591911792755127,\n",
       "  0.8490281105041504,\n",
       "  0.8712567687034607,\n",
       "  0.9004629254341125,\n",
       "  0.9134267568588257,\n",
       "  0.869975209236145,\n",
       "  0.8575289845466614,\n",
       "  0.9173118472099304,\n",
       "  0.8792150020599365,\n",
       "  0.8764635324478149,\n",
       "  0.9174087047576904,\n",
       "  0.9616391658782959,\n",
       "  0.9553048014640808,\n",
       "  0.9310934543609619,\n",
       "  0.9205513000488281,\n",
       "  0.9112019538879395,\n",
       "  0.949506402015686,\n",
       "  0.8764290809631348,\n",
       "  0.9681757092475891,\n",
       "  0.9542180895805359,\n",
       "  0.9261411428451538,\n",
       "  0.9596329927444458,\n",
       "  0.9421447515487671,\n",
       "  0.965897798538208,\n",
       "  0.9765644073486328,\n",
       "  0.973964273929596,\n",
       "  0.9144518971443176,\n",
       "  0.9366933703422546,\n",
       "  0.8493096828460693,\n",
       "  0.9814470410346985,\n",
       "  0.8960756659507751,\n",
       "  0.9357150793075562,\n",
       "  0.9051939249038696,\n",
       "  0.9218935966491699,\n",
       "  0.902848482131958,\n",
       "  0.8954634666442871,\n",
       "  0.92963045835495,\n",
       "  0.9319903254508972,\n",
       "  0.864488959312439,\n",
       "  0.8894701600074768,\n",
       "  0.9277705550193787,\n",
       "  0.9406512975692749,\n",
       "  0.9137047529220581,\n",
       "  0.9401677250862122,\n",
       "  0.9031839966773987,\n",
       "  0.9301586151123047,\n",
       "  0.8246414661407471,\n",
       "  0.8289206027984619,\n",
       "  0.8580449819564819,\n",
       "  0.9240221977233887,\n",
       "  0.8314003944396973,\n",
       "  0.8987444043159485,\n",
       "  0.8898907899856567,\n",
       "  0.9125360250473022,\n",
       "  0.9336791038513184,\n",
       "  0.9148753881454468,\n",
       "  0.9247076511383057,\n",
       "  0.9812535047531128,\n",
       "  0.9726315140724182,\n",
       "  0.6858153343200684,\n",
       "  0.8763875365257263,\n",
       "  0.8764363527297974,\n",
       "  0.9817094206809998,\n",
       "  0.9138898849487305,\n",
       "  0.9576482176780701,\n",
       "  0.9223185777664185,\n",
       "  0.9461967349052429,\n",
       "  0.8745495080947876,\n",
       "  0.8759143948554993,\n",
       "  0.8989195823669434,\n",
       "  0.9336585998535156,\n",
       "  0.8851758241653442],\n",
       " 'recall': [0.9547595977783203,\n",
       "  0.8768235445022583,\n",
       "  0.8701650500297546,\n",
       "  0.8724895119667053,\n",
       "  0.8919954299926758,\n",
       "  0.9127845168113708,\n",
       "  0.971820592880249,\n",
       "  0.8833215832710266,\n",
       "  0.8134944438934326,\n",
       "  0.9350863695144653,\n",
       "  0.9360430240631104,\n",
       "  0.877147912979126,\n",
       "  0.8906359076499939,\n",
       "  0.93255215883255,\n",
       "  0.8897843360900879,\n",
       "  0.9214850068092346,\n",
       "  0.8997873663902283,\n",
       "  0.8826208710670471,\n",
       "  0.909986138343811,\n",
       "  0.8039708733558655,\n",
       "  0.8388998508453369,\n",
       "  0.8518897294998169,\n",
       "  0.8073717951774597,\n",
       "  0.8405108451843262,\n",
       "  0.8928524255752563,\n",
       "  0.9794473648071289,\n",
       "  0.9188440442085266,\n",
       "  0.8673884868621826,\n",
       "  0.8592002391815186,\n",
       "  0.8333409428596497,\n",
       "  0.8067978620529175,\n",
       "  0.8429160714149475,\n",
       "  0.8424520492553711,\n",
       "  0.8865461945533752,\n",
       "  0.8853937983512878,\n",
       "  0.8936476707458496,\n",
       "  0.8666773438453674,\n",
       "  0.8633467555046082,\n",
       "  0.8473672866821289,\n",
       "  0.8981942534446716,\n",
       "  0.9209871292114258,\n",
       "  0.9288763403892517,\n",
       "  0.9042433500289917,\n",
       "  0.8646378517150879,\n",
       "  0.8954589366912842,\n",
       "  0.8404578566551208,\n",
       "  0.9266603589057922,\n",
       "  0.9343223571777344,\n",
       "  0.887637734413147,\n",
       "  0.9594280123710632,\n",
       "  0.886951744556427,\n",
       "  0.926744282245636,\n",
       "  0.8685284852981567,\n",
       "  0.9626044631004333,\n",
       "  0.8782570362091064,\n",
       "  0.924307107925415,\n",
       "  0.8699994683265686,\n",
       "  0.8759679794311523,\n",
       "  0.8332290053367615,\n",
       "  0.9111076593399048,\n",
       "  0.8701748251914978,\n",
       "  0.8734545707702637,\n",
       "  0.8577300906181335,\n",
       "  0.8945637345314026,\n",
       "  0.8915790319442749,\n",
       "  0.9169257283210754,\n",
       "  0.8416346907615662,\n",
       "  0.886851966381073,\n",
       "  0.9092720746994019,\n",
       "  0.9130194187164307,\n",
       "  0.8776178359985352,\n",
       "  0.8614794015884399,\n",
       "  0.8770641088485718,\n",
       "  0.8924305438995361,\n",
       "  0.866651177406311,\n",
       "  0.8412114977836609,\n",
       "  0.8802307844161987,\n",
       "  0.8601354360580444,\n",
       "  0.79072105884552,\n",
       "  0.8861855864524841,\n",
       "  0.8616617918014526,\n",
       "  0.8757155537605286,\n",
       "  0.8908236622810364,\n",
       "  0.8745582699775696,\n",
       "  0.8587645292282104,\n",
       "  0.877185583114624,\n",
       "  0.961227297782898,\n",
       "  0.8217793107032776,\n",
       "  0.8229272961616516,\n",
       "  0.8976417779922485,\n",
       "  0.876007080078125,\n",
       "  0.8482540249824524,\n",
       "  0.9289687871932983,\n",
       "  0.8538877964019775,\n",
       "  0.8792275786399841,\n",
       "  0.8357496857643127,\n",
       "  0.8364827632904053,\n",
       "  0.8470938801765442,\n",
       "  0.9336585998535156,\n",
       "  0.8730789422988892],\n",
       " 'f1': [0.9688118696212769,\n",
       "  0.8943177461624146,\n",
       "  0.9008294343948364,\n",
       "  0.9022983908653259,\n",
       "  0.9032483100891113,\n",
       "  0.9338847398757935,\n",
       "  0.971820592880249,\n",
       "  0.8942363858222961,\n",
       "  0.8284408450126648,\n",
       "  0.9479579329490662,\n",
       "  0.9362800121307373,\n",
       "  0.8568504452705383,\n",
       "  0.8959498405456543,\n",
       "  0.9417151212692261,\n",
       "  0.9079681634902954,\n",
       "  0.9401168823242188,\n",
       "  0.9207397103309631,\n",
       "  0.8946100473403931,\n",
       "  0.8769030570983887,\n",
       "  0.8093092441558838,\n",
       "  0.8483433723449707,\n",
       "  0.848468005657196,\n",
       "  0.8205540180206299,\n",
       "  0.8595134615898132,\n",
       "  0.8998010158538818,\n",
       "  0.9880040287971497,\n",
       "  0.9207304120063782,\n",
       "  0.9246041774749756,\n",
       "  0.8591957688331604,\n",
       "  0.841111421585083,\n",
       "  0.8377893567085266,\n",
       "  0.8707396984100342,\n",
       "  0.8765049576759338,\n",
       "  0.8781824707984924,\n",
       "  0.871238648891449,\n",
       "  0.9053251147270203,\n",
       "  0.872901201248169,\n",
       "  0.8698557019233704,\n",
       "  0.8809980750083923,\n",
       "  0.9288344979286194,\n",
       "  0.9378321170806885,\n",
       "  0.9299835562705994,\n",
       "  0.9123244881629944,\n",
       "  0.8873094320297241,\n",
       "  0.9216910004615784,\n",
       "  0.8580666184425354,\n",
       "  0.9469632506370544,\n",
       "  0.9441654086112976,\n",
       "  0.9064807295799255,\n",
       "  0.9595305323600769,\n",
       "  0.9137154817581177,\n",
       "  0.9459161162376404,\n",
       "  0.9193834662437439,\n",
       "  0.9682510495185852,\n",
       "  0.8959891200065613,\n",
       "  0.9304589629173279,\n",
       "  0.8595301508903503,\n",
       "  0.9257125854492188,\n",
       "  0.8635103106498718,\n",
       "  0.9232473969459534,\n",
       "  0.8873390555381775,\n",
       "  0.8970206379890442,\n",
       "  0.8797110915184021,\n",
       "  0.8950133919715881,\n",
       "  0.910207211971283,\n",
       "  0.9243966937065125,\n",
       "  0.8529087901115417,\n",
       "  0.8881591558456421,\n",
       "  0.9184282422065735,\n",
       "  0.9266294240951538,\n",
       "  0.8952977657318115,\n",
       "  0.8991051912307739,\n",
       "  0.88993239402771,\n",
       "  0.9109041094779968,\n",
       "  0.8451246023178101,\n",
       "  0.8350207805633545,\n",
       "  0.8689963221549988,\n",
       "  0.8909350037574768,\n",
       "  0.8105506300926208,\n",
       "  0.892420768737793,\n",
       "  0.8755488395690918,\n",
       "  0.8937466740608215,\n",
       "  0.9117480516433716,\n",
       "  0.8942626118659973,\n",
       "  0.890516996383667,\n",
       "  0.9263057708740234,\n",
       "  0.9668957591056824,\n",
       "  0.7476663589477539,\n",
       "  0.848816454410553,\n",
       "  0.8869123458862305,\n",
       "  0.925851047039032,\n",
       "  0.8798496127128601,\n",
       "  0.943090558052063,\n",
       "  0.8867850303649902,\n",
       "  0.9114837646484375,\n",
       "  0.8547094464302063,\n",
       "  0.8557446002960205,\n",
       "  0.8722376227378845,\n",
       "  0.9336585998535156,\n",
       "  0.8790857791900635],\n",
       " 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.27.4)'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92bce9fe84da40da91ee0aec617bf116",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/5.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default BLEURT-Base checkpoint for sequence maximum length 128. You can use a bigger model for better results with e.g.: evaluate.load('bleurt', 'bleurt-large-512').\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6df96feb39d49c8b42be8c0f1ee2fa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/405M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reading checkpoint C:\\Users\\warri\\.cache\\huggingface\\metrics\\bleurt\\default\\downloads\\extracted\\7e2b9c93b3d13a3158b0a4c5cbd5b1c8c8485d4008aba3a3ecee51b58f511b4c\\bleurt-base-128.\n",
      "INFO:tensorflow:Config file found, reading.\n",
      "INFO:tensorflow:Will load checkpoint bert_custom\n",
      "INFO:tensorflow:Loads full paths and checks that files exists.\n",
      "INFO:tensorflow:... name:bert_custom\n",
      "INFO:tensorflow:... vocab_file:vocab.txt\n",
      "INFO:tensorflow:... bert_config_file:bert_config.json\n",
      "INFO:tensorflow:... do_lower_case:True\n",
      "INFO:tensorflow:... max_seq_length:128\n",
      "INFO:tensorflow:Creating BLEURT scorer.\n",
      "INFO:tensorflow:Creating WordPiece tokenizer.\n",
      "INFO:tensorflow:WordPiece tokenizer instantiated.\n",
      "INFO:tensorflow:Creating Eager Mode predictor.\n",
      "INFO:tensorflow:Loading model.\n",
      "INFO:tensorflow:BLEURT initialized.\n"
     ]
    }
   ],
   "source": [
    "bleurt = evaluate.load(\"bleurt\", module_type=\"metric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [\"hello there\", \"general kenobi\"]\n",
    "references = [\"hello there\", \"general kenobi\"]\n",
    "results = bleurt.compute(predictions=predictions, references=references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'scores': [1.0295476913452148, 1.0445424318313599]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
